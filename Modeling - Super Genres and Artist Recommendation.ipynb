{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spotify Artist Recommendation Project - Modeling\n",
    "\n",
    "We explored the time components of the data in each song in the [previous notebook](https://github.com/dvanheeswijk/Spotify/blob/master/Data%20Wrangling%20and%20EDA.ipynb). Now we will look to perform the task of creating an artist recommendation model. To do this, we begin by reading in the [data](https://www.kaggle.com/yamaerenay/spotify-dataset-19212020-160k-tracks) and libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from random import sample\n",
    "\n",
    "from sklearn.preprocessing import Normalizer, MinMaxScaler\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/data.csv')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre = pd.read_csv('data/data_by_genres.csv')\n",
    "\n",
    "genre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists = pd.read_csv('data/data_w_genres.csv')\n",
    "\n",
    "artists.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the three data sets to help with some of the modeling. The majority of the data we will use in modeling and training/testing will be part of the **data** dataframe. The *genre* and *artists* dataframes will help with distinguishing how our model has done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genre Clusters\n",
    "\n",
    "We would like to create a model that clusters genres of songs together based on the commonality in audio features. In order to do this, we will need to clean the data just a bit to get what we want, before scaling and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = genre.columns\n",
    "\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = columns[1:]\n",
    "X = genre[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For our model to work best, we need to normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(X)\n",
    "\n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = pd.DataFrame(X_scaled, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans()\n",
    "\n",
    "n_clusters = range(1, 100)\n",
    "error = []\n",
    "for n in n_clusters:\n",
    "    kmeans = KMeans(n_clusters=n)\n",
    "    kmeans.fit(X_scaled)\n",
    "    error.append(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(n_clusters,error)\n",
    "plt.xlabel('Number of Genres')\n",
    "plt.ylabel('Sum of squared distances')\n",
    "plt.title('Evaluation for # of clusters vs error')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that our best estimate for the number of clusters to use to create our \"Super\" Genres would be right around 20 or so genres. Thus we will create our \"Super\" genres using 20 clusters and apply them to the already existing genre data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_kmeans = KMeans(n_clusters=20)\n",
    "\n",
    "super_genres = best_kmeans.fit_predict(X_scaled)\n",
    "\n",
    "genre['super_genre'] = super_genres\n",
    "\n",
    "genre.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's take a quick look at our 20 super genres to confirm that they make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_count = genre.groupby('super_genre')['genres'].count()\n",
    "\n",
    "plt.figure(figsize=(12,7))\n",
    "sns.barplot(x = genre_count.index, y=genre_count, color='gray')\n",
    "plt.title('Number of genres per super genre')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the number of genres per super genre ranges dramatically from one with about 10 total genres to some with nearly 250. We will investigate a couple super genres to see if the combinations make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(genre[genre['super_genre']==17]['genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from super genre 4\n",
    "print(sample(list(genre[genre['super_genre']==4]['genres']),15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from super genre 0\n",
    "print(sample(list(genre[genre['super_genre']==0]['genres']),15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from super genre 12\n",
    "print(sample(list(genre[genre['super_genre']==12]['genres']),15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from super genre 18\n",
    "print(sample(list(genre[genre['super_genre']==18]['genres']),15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from super genre 3\n",
    "print(sample(list(genre[genre['super_genre']==3]['genres']),15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that the super genres tend to have some similarities that pop out. When we look at super genre 17, we find that it is full of genres that are more spoken word like comedy, poetry, and reading. However, we also see that there are a few genres that maybe don't have as much in common with comedy, such as classic hungarian pop.\n",
    "\n",
    "Looking at a few other super genres gives us the feeling that, within each super genre, there are smaller clusters of similar genres that are put together in the super genre. For example, in super genre 18, there are indie folk, brooklyn indie, and piano rock together in the same super genre as trap, scam rap, and manchester hip hop. Clearly the first three have similarities to each other, but not as much with the second three. To remedy this, we would need to either create more super genres, or recognize that this phenomena will happen with fewer super genres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artist Recommendation\n",
    "\n",
    "We will now switch to our other task, which is to create an artist recommendation model. To do this, we will use the data and artists dataframes to create our training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists = pd.read_csv('data/data_w_genres.csv')\n",
    "\n",
    "artists.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we had before, we are going to need to cluster the artists genres based on the data available. Thus, we will create another cluster to create \"genres\" for each artists, given the audio features for each given artist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "artists[columns] = scaler.fit_transform(artists[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KMeans(n_clusters=20)\n",
    "\n",
    "artists['genres'] = knn.fit_predict(artists[columns])\n",
    "\n",
    "artists.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a cluster for artists, we can look into creating a recommendation system for a given user. The way we will do this is by creating a set of \"users\" that have first rated song on a scale of 1-10. We will then use the user rating data to create a recommendation of 5 artists based on preference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists['user_id'] = np.random.randint(1000,1500,len(artists))\n",
    "artists['rating'] = np.random.randint(1,11,len(artists))\n",
    "\n",
    "artists.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(user_id):\n",
    "    user_genres =  list(dict.fromkeys(artists[artists['user_id']==user_id].sort_values('rating', ascending=False)['genres'][:5]))\n",
    "    new_artists = artists[artists['genres'].isin(user_genres)].sort_values('popularity',ascending=False)['artists']\n",
    "    return sample(list(new_artists),10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend(1014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists[artists['user_id']==1014].sort_values('rating',ascending=False)[['artists','genres', 'rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Song Recommendation\n",
    "\n",
    "What we would really like to do is create a recommendation for songs based on a listener's previously played songs. For this purpose, we are going to create a fake list of users and how many times they listened to certain songs. With this, we will then take each user's top 5 songs, and recommend the next song as a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['artists'] = data['artists'].str.replace('\"', '').str.replace(\"'\",\"\").str.replace('[','').str.replace(']','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "data[columns] = scaler.fit_transform(data[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a \"decade\" feature which may help with recommendations\n",
    "data['decade'] = pd.qcut(data['year'],10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(inplace=True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['id'].is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns='index',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We dropped a few duplicated rows and have discerned that the 'id' column holds a unique index for each song. We will use this as our independent variable, then convert the id to its corresponding artists/song recommendation.\n",
    "\n",
    "Now, we are ready to make a dummy user with a play count for each song. We will make the listening set sparse by filling the majority of the songs with 0, then focus on 25000 songs to place randomized listening habits. For the sake of this exercise, songs will be played no more than 100 times by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['user_play_count'] = 0\n",
    "\n",
    "listeners_list = [np.random.randint(0,len(data)) for i in range(0,25000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in listeners_list:\n",
    "    data.loc[i,'user_play_count'] = np.random.randint(0,101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data[data['user_play_count']>0]['user_play_count'],bins=25)\n",
    "plt.title('Random User listens count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KMeans(n_clusters=25)\n",
    "\n",
    "data['genre'] = knn.fit_predict(data[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['genre']\n",
    "X = data[['user_play_count', 'year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "learning_rate = [0.001,0.01, 0.1]\n",
    "n_estimators = [10,50,100]\n",
    "subsample = [0.5, 0.7, 1.0]\n",
    "max_depth = [3, 7, 9]\n",
    "\n",
    "grid = dict(learning_rate=learning_rate, n_estimators=n_estimators, subsample=subsample, max_depth=max_depth)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = RandomizedSearchCV(estimator=gb, param_distributions=grid, n_iter=8, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class song_recommendation():\n",
    "    def __init__(self):\n",
    "        self.train_data = None\n",
    "        self.user_id = None\n",
    "        self.item_id = None\n",
    "        \n",
    "    def "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
